# CCSW325-codetranslation

<h2>The main Idea of each paper</h2>
<h3>1- Unraveling the Potential of Large Language Models in Code Translation:</h3>
<p>
    This study investigates the effectiveness of Large Language Models (LLMs) in code translation, focusing on their limitations due to inadequate training on parallel multilingual code data. The authors propose a novel benchmark, PolyHumanEval, which includes 14 programming languages to provide a comprehensive framework for evaluating LLM performance in code translation. The research aims to uncover the capabilities and limitations of LLMs in translating code between different programming languages.
</p>

<h3>2- Exploring and Unleashing the Power of Large Language Models in Automated Code Translation:</h3>
<p>
    This research investigates the possibilities of Large Language odels (LLMs), traditional code translation tools, or transpilers, have limitations with regard to correctness and practical eployment. The study examines how well LLMs succeed in getting over these restrictions and suggests a brand-new framework named UniTrans to improve the caliber of code translation.
 </p>

<h3>3- TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation:</h3>
<p>
    Code translation converts code from one programming language to another while maintaining its original functionality, which is crucial for software migration, system refactoring, and cross-platform development.
 </p>

<h3>4- Towards Translating Real-World Code with LLMs: A Study of Translating to Rust:</h3>
<p>
    The study investigates the effectiveness of large language models (LLMs) in translating real-world code into Rust. It focuses on assessing the capabilities of five state-of-the-art LLMs—GPT-4, Claude 3, Claude 2.1, Gemini Pro, and Mixtral—highlighting the challenges and methodologies for achieving accurate and idiomatic translations.
 </p>

<h3>5- Lost in Translation A Study:</h3>
<p>
    The study investigates the effectiveness and limitations of Large Language Models (LLMs) in translating code between different programming languages. It aims to understand the bugs introduced during this translation process and proposes methods to improve LLM performance through enhanced prompting techniques.
 </p>
